{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install pandas\n",
    "# !pip install seaborn\n",
    "# !pip install scikit-learn\n",
    "# !pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, r_regression\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1A : Brief Description of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The World Happiness Report\n",
    "\n",
    "* The World Happiness Report reviews the state of happiness across a multitude of countries based on a series of questions, with answers rated between 0 and 10. Six variables are then used to explain the overall 'happiness', comparing the outcome against a fictional country called Dystopia, which is a culmination of all the lowest ratings gathered that year.\n",
    "\n",
    "https://worldhappiness.report/about/\n",
    "\n",
    "* The data and inforation regrarding it was sourced from : https://worldhappiness.report/data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_report = pd.read_excel('data/DataForTable2.1WHR2023.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1A Summary Statistics: Happiness Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_report.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2A Column Headers: Happiness Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(happiness_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3B Graphs : Happiness Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = happiness_report['Country name']\n",
    "happiness = happiness_report['Life Ladder']\n",
    "\n",
    "plt.figure(figsize=(30, 6))\n",
    "plt.bar(countries, happiness, color='orange')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Life Ladder  (%)')\n",
    "plt.title('Happiness Across Countries')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B : Brief Description of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### World Educational Data\n",
    "\n",
    "* The World Educational Data contains information on various educational indicators from countries around the world. It includes a range of variables related to education, such as literacy rates, enrollment rates, birth rates, and unemployment rates.\n",
    "\n",
    "* The data is taken from sources which were last updated in 2021.\n",
    "\n",
    "* The data and inforation regarding it was sourced from : https://www.kaggle.com/datasets/nelgiriyewithana/world-educational-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_report = pd.read_excel('data/education_world.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1B Summary Statistics: Education Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_report.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2B Column Headers : Education Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(education_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3B Graphs : Education Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = education_report['Countries and areas']\n",
    "unemployment_rates = education_report['Unemployment_Rate']\n",
    "\n",
    "plt.figure(figsize=(30, 6))\n",
    "plt.bar(countries, unemployment_rates, color='orange')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Unemployment Rate (%)')\n",
    "plt.title('Unemployment Rates Across Countries')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Linking Data from Different Sources\n",
    "\n",
    "I am going to explore the correlation between educational 'success' and perceived happiness. I also want to examine gender disparity in education and its potential effect on purported happiness.\n",
    "\n",
    "I aim to develop a predictive model to forecast happiness scores based on gender disparities in education indicators, such as enrollment rates and literacy rates between males and females."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justification for Predicting Happiness Scores\n",
    "\n",
    "Happiness is an important indicator of human well-being and quality of life. Gaining an understanding of the critical factors that dictate happiness, as well as the correlation between education and happiness, could offer insights into areas of society that could be highlighted and improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1a Clean the Data : Happiness Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1a Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(happiness_report.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_columns_null = (happiness_report.isnull().sum() / len(happiness_report)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of null values in the Data\")\n",
    "print(percent_columns_null.apply(lambda x: \"{:.2f}%\".format(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of columns have a number of null values, but overall the percentage is low. I decided to perform imputation using the mean value of the column, using SimpleImputer from the scikitlearn module. (scikit-learn, 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_missing_values = ['Log GDP per capita', 'Social support', 'Healthy life expectancy at birth', 'Freedom to make life choices', 'Generosity', 'Perceptions of corruption', 'Positive affect', 'Negative affect']\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "happiness_report[columns_with_missing_values] = imputer.fit_transform(happiness_report[columns_with_missing_values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing imputation check that the report no longer contains null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_report.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2a Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(happiness_report.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3a Check for Inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Unique Country Names: \", happiness_report['Country name'].nunique())\n",
    "print(\"Total Number of Country Names: \", happiness_report['Country name'].shape[0])\n",
    "print(\"Count of Unique Country Names\", happiness_report['Country name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1b Clean the Data : Education Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1b Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(education_report.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1b Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(education_report.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3b Check for Inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Unique Country Names\", education_report['Countries and areas'].nunique())\n",
    "print(\"Total Number of Country Names\", education_report['Countries and areas'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Collate based on Country Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hapiness has 165, education has 202. Compare and print unmatching countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_countries = happiness_report['Country name'].unique()\n",
    "education_countries = education_report['Countries and areas'].unique()\n",
    "\n",
    "matching_countries = set(happiness_countries).intersection(education_countries)\n",
    "\n",
    "print(\"Matching Countries:\")\n",
    "for country in matching_countries:\n",
    "    print(country)\n",
    "\n",
    "print(\"Total matching countries: \", len(matching_countries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Link the Datasets  : Happiness dataset and Education Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Merge on a common column (country)\n",
    "* Ensure the column names match\n",
    "* Remove the log/lat from education as not necessary\n",
    "* Remove unmatching country rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_happiness_report = happiness_report[happiness_report['Country name'].isin(matching_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_education_report = education_report[education_report['Countries and areas'].isin(matching_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_education_report['Countries and areas'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_education_report = new_education_report.drop(columns=['Latitude ', 'Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_education_report.rename(columns={'Countries and areas': 'Country name'}, inplace=True)\n",
    "new_education_report.rename(columns={'Countries and areas': 'Country name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two tables on the column name 'Country name' after changing the column name in the eductaion dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_table = new_happiness_report.merge(new_education_report, on='Country name', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the education report is based off date from 2021 I decided to remove all other years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_table = merged_table[merged_table['year'] == 2021]\n",
    "merged_table.drop(columns=['year'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph showing correlation between Happiness score (life ladder) and gross primary vs gross tertiary education using Plotly's Python graphing library. (plotly, 2024) This shows that there is a correlation between third level education and perceived happiness, more significantly affected than primary school enrollment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_score = merged_table['Life Ladder']\n",
    "gross_primary = merged_table['Gross_Primary_Education_Enrollment']\n",
    "gross_sec = merged_table['Gross_Tertiary_Education_Enrollment']\n",
    "countries = merged_table['Country name']\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('Gross_Primary_Education_Enrollment', 'Gross_Tertiary_Education_Enrollment'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=happiness_score, y=gross_primary, mode='markers',\n",
    "                         marker=dict(color='orange'),\n",
    "                         text=countries,\n",
    "                         name='Primary'), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=happiness_score, y=gross_sec, mode='markers',\n",
    "                         marker=dict(color='green'),\n",
    "                         text=countries,\n",
    "                         name='Tertiary'), row=1, col=2)\n",
    "\n",
    "fig.update_layout(title='Happiness Score vs Literacy Rate',\n",
    "                  xaxis_title='Happiness Score',\n",
    "                  yaxis_title='Gross Enrollment',\n",
    "                  legend_title='Level')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4 : Choose and train Estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Correlation Heatmap\n",
    "As my dataset currently has more than 33 columns, I decided to generate a heatmap to observe the features with the highest correlation and then to only use these columns in training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged_table.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merged.corr()\n",
    "plt.figure(figsize=(30,6))\n",
    "sns.heatmap(corr,\n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values,\n",
    "            cmap=\"BuPu\",\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            annot=True)\n",
    "plt.title(\"Correlation Heatmap of mtcars dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above heatmap we can see there is high correlation between life ladder and the following: Log GPD per capita, Social support, Healthy life expectancy at birth, Lower_Secondary_End_Proficiency_Reading, Gross_Tertiary_Education_Enrollment, and Lower_Secondary_End_Proficiency_Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['Log GDP per capita', 'Social support', 'Healthy life expectancy at birth', 'Lower_Secondary_End_Proficiency_Reading', 'Gross_Tertiary_Education_Enrollment', 'Lower_Secondary_End_Proficiency_Math']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 SelectKBest\n",
    " I also explored feature selection using scikit-learn module, as demonstrated in the tutorial 'How to Build a Predictive Model in Python?' (365 Data Science, 2022). It was necessaryy to remove the Generosity column as it contained negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_table = merged_table.drop(columns=['Generosity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= selected_features_table.iloc[:,2:]\n",
    "Y= selected_features_table.iloc[:,1]\n",
    "\n",
    "best_features= SelectKBest(score_func=r_regression, k= 6)\n",
    "fit= best_features.fit(X,Y)\n",
    "\n",
    "df_scores= pd.DataFrame(fit.scores_)\n",
    "df_columns= pd.DataFrame(X.columns)\n",
    "\n",
    "features_scores= pd.concat([df_columns, df_scores], axis=1)\n",
    "features_scores.columns= ['Features', 'Score']\n",
    "features_scores.sort_values(by = 'Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the top six features match the six features highlighted earlier as being the most correlated to the life ladder variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = merged_table[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Split the Dataset\n",
    "Split the updated dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = merged_table.columns[1:]\n",
    "target = merged_table.columns[1]\n",
    "y = merged_table[target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Choose Estimator\n",
    "The next step was to create the ElasticNet Linear Regression Model. I chose this model based on scikit-learn's machine learning map tutorial (scikit-learn, 2024).\n",
    "This estimator also highlighted the Lasso Linear Regression option as potentially relevant for my project. I decided to implement and evaluate both to see which would be the better fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Create and train the ElasticNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = alpha (weight of penalties) & lambda (overall strength of regularisation)\n",
    "elastic_model = ElasticNet()\n",
    "elastic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 Create and train the Lasso Model\n",
    "The lasso model also automatically selects relevant features improving generalisation. (Saturn Cloud, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = Lasso()\n",
    "lasso_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Create and Train the SGD Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Stochastic Gradient Descent Model (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model = SGDRegressor()\n",
    "sgd_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4 Generate Predictions for all Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_predictions = elastic_model.predict(X_test)\n",
    "lasso_predictions = lasso_model.predict(X_test)\n",
    "sgd_predictions = sgd_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 5 : Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Evaluate by Calculating Mean Squared Error(MSE)\n",
    "Calculate MSE to measure the distance between the actual and predicted values for both the Elastic model and the Lasso model. (Daniel, S., (2022))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_mse = mean_squared_error(y_test, elastic_predictions)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_predictions)\n",
    "sgd_mse = mean_squared_error(y_test, sgd_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Elastic MSE:\", elastic_mse)\n",
    "print(\"Lasso MSE:\", lasso_mse)\n",
    "print(\"SGD MSE:\", sgd_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result shows a more accurate result for the Lasso model, then the Elastic model. The SGD model performed the worst with the default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Evaluate by Calculating the R squared\n",
    "\n",
    "Calculating the R squared measures the 'goodness of fit' of a regression model by comparing how the model fits the data comapred to a mean line ranging from 0 to 1, where the higher the value the better the fit. (Daniel, S., (2022))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_r2 = r2_score(y_test, elastic_predictions)\n",
    "lasso_r2 = r2_score(y_test, lasso_predictions)\n",
    "sgd_r2 = r2_score(y_test, sgd_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Elastic R2:\", elastic_r2)\n",
    "print(\"Lasso R2:\", lasso_r2)\n",
    "print(\"SGD R2:\", sgd_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result again shows a much better result for the Lasso and Elastic model, while the SGD model performs very poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Fine Tune and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Fine Tuning the Lasso Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a loop to traverse the number of alpha values to be checked, each time checking the mse and r2, eventually outputting the best possible model and alpha parameter, based off mse and r2 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1.1 Feature Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fine tuning, I normalised the data using StandardScalar and RobustScalar to determine which would improve the results. Normalisation helps standardise the features, ultimately resulting in better overall model performance.  (atoti, n.d.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.1.1.1 Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train_robust_scaled = scaler.fit_transform(X_train)\n",
    "X_test_robust_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.1.1.2 Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = np.linspace(0.0001, 1, 100)\n",
    "\n",
    "best_alpha = None\n",
    "best_lasso_model = None\n",
    "best_mse = float(\"inf\")\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    lasso_model.fit(X_train_robust_scaled, y_train)\n",
    "    lasso_predictions = lasso_model.predict(X_test_robust_scaled)\n",
    "    lasso_mse = mean_squared_error(y_test, lasso_predictions)\n",
    "    \n",
    "    if lasso_mse < best_mse:\n",
    "        best_alpha = alpha\n",
    "        best_lasso_model = lasso_model\n",
    "        best_mse = lasso_mse\n",
    "\n",
    "lasso_predictions = best_lasso_model.predict(X_test_robust_scaled)\n",
    "lasso_r2 = r2_score(y_test, lasso_predictions)\n",
    "\n",
    "print(\"Best Lasso Model:\")\n",
    "print(\"Alpha:\", best_alpha)\n",
    "print(\"MSE:\", best_mse)\n",
    "print(\"R2:\", lasso_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data beforehand gave a slight improvement of both MSE and r2 score using the StandardScalar, but the RobustScaler gave a better result.\n",
    "RobustScaler is normally used in cases of data with outliers. Interestingly, it provided a better outcome in the case of the Lasso model. scikit-learn (n.d.) \n",
    "\n",
    "\n",
    "Results Before Normalisation\n",
    "* Alpha: 0.010199999999999999\n",
    "* MSE: 0.3856511937788607\n",
    "* R2: 0.7477302731110707\n",
    "\n",
    "Standard Scaler Results\n",
    "* Alpha: 0.0203\n",
    "* MSE: 0.38404698653221486\n",
    "* R2: 0.74877964863619\n",
    "\n",
    "RobustScaler Results\n",
    "* Alpha: 0.0203\n",
    "* MSE: 0.37841943260160277\n",
    "* R2: 0.7524608546483313\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Fine Tuning the ElasticNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following works the same as for the Lasso model except that the inner loop additionally iterates over different values of the 'L1 ratio' parameter, 0 - 1. (scikit-learn, n.d.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2.1 Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the same results from feature scaling earlier for the ElasticNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = np.linspace(0.01, 1, 100)\n",
    "l1_ratio_values = np.linspace(0, 1, 100)\n",
    "max_iter = 10000\n",
    "\n",
    "best_alpha = None\n",
    "best_l1_ratio = None\n",
    "best_elastic_model = None\n",
    "best_mse = float(\"inf\")\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    for l1_ratio in l1_ratio_values:\n",
    "        elastic_model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, max_iter=max_iter)\n",
    "        elastic_model.fit(X_train_scaled, y_train)\n",
    "        elastic_predictions = elastic_model.predict(X_test_scaled)\n",
    "        elastic_mse = mean_squared_error(y_test, elastic_predictions)\n",
    "\n",
    "        if elastic_mse < best_mse:\n",
    "            best_alpha = alpha\n",
    "            best_l1_ratio = l1_ratio\n",
    "            best_elastic_model = elastic_model\n",
    "            best_mse = elastic_mse\n",
    "\n",
    "best_elastic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "elastic_predictions = best_elastic_model.predict(X_test_scaled)\n",
    "elastic_mse = mean_squared_error(y_test, elastic_predictions)\n",
    "elastic_r2 = r2_score(y_test, elastic_predictions)\n",
    "\n",
    "print(\"Best Elastic Model\")\n",
    "print(\"Alpha: \", best_alpha)\n",
    "print(\"L1 Ratio: \", best_l1_ratio)\n",
    "print(\"MSE: \", elastic_mse)\n",
    "print(\"R2: \", elastic_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the ElasticNet Model, scaling the features using StandardScaler not only improved the MSE and R2 results, it also reduced convergance time significantly.\n",
    "\n",
    "Interestingly, in the case of the ElasticNet model, it also performed better using the RobustScaler. This may be due to a difference in sensitivity to scaling by the model. Ouput as follows:\n",
    "\n",
    "RobustScaler Results\n",
    "* Alpha:  0.02\n",
    "* L1 Ratio:  0.3434343434343435\n",
    "* MSE:  0.37697763615039054\n",
    "* R2:  0.7534039908367942\n",
    "\n",
    "StandardScaler Results\n",
    "* Alpha:  0.05\n",
    "* L1 Ratio:  0.21212121212121213\n",
    "* MSE:  0.3812524170788433\n",
    "* R2:  0.750607687247626\n",
    "\n",
    "No Scaler Results\n",
    "* Alpha:  0.01\n",
    "* L1 Ratio:  0.9393939393939394\n",
    "* MSE:  0.3851970694655492\n",
    "* R2:  0.7480273338186239"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 Fine Tuning the SGD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = np.linspace(0.0001, 1, 100)\n",
    "l1_ratio_values = np.linspace(0, 1, 100)\n",
    "max_iter = 1000\n",
    "\n",
    "best_alpha = None\n",
    "best_sgd_model = None\n",
    "best_l1_ratio = None\n",
    "best_mse = float(\"inf\")\n",
    "\n",
    "random_state = 42\n",
    "for alpha in alpha_values:\n",
    "    for l1_ratio in l1_ratio_values:\n",
    "        sgd_model = SGDRegressor(alpha=alpha, max_iter=max_iter, l1_ratio=l1_ratio, random_state=random_state)\n",
    "        sgd_model.fit(X_train_robust_scaled, y_train)\n",
    "        sgd_predictions = sgd_model.predict(X_test_robust_scaled)\n",
    "        sgd_mse = mean_squared_error(y_test, sgd_predictions)\n",
    "        \n",
    "        if sgd_mse < best_mse:\n",
    "            best_alpha = alpha\n",
    "            best_sgd_model = sgd_model\n",
    "            best_l1_ratio = l1_ratio\n",
    "            best_mse = sgd_mse\n",
    "\n",
    "sgd_predictions = best_sgd_model.predict(X_test_robust_scaled)\n",
    "sgd_r2 = r2_score(y_test, sgd_predictions)\n",
    "\n",
    "print(\"Best SGD Model:\")\n",
    "print(\"Alpha:\", best_alpha)\n",
    "print(\"L1 ratio: \", best_l1_ratio)\n",
    "print(\"MSE:\", best_mse)\n",
    "print(\"R2:\", sgd_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the SGD model features vastly improved the scores. The SGD model is very sensitive to feature scaling and performs much better on normalised data, so this result is not surprising. In the case of the SGD model, the RobustScaler performed slightly better, as can be seen below.\n",
    "\n",
    "RobustScaler Results\n",
    "* Alpha: 0.0203\n",
    "* L1 ratio:  0.0\n",
    "* MSE: 0.38770354856706724\n",
    "* R2: 0.7463877465216238\n",
    "\n",
    "StandardScalar Results\n",
    "* Alpha: 0.13\n",
    "* MSE: 0.39239607587197767\n",
    "* R2: 0.7433181784748374\n",
    "\n",
    "No Scaling Results\n",
    "* Best SGD Model:\n",
    "* Alpha: 1.0\n",
    "* MSE: 6.542468966072278e+23\n",
    "* R2: -4.279688189418018e+23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.4 Scatter Plot of Actual vs Predicted Values of All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "axes[0].scatter(y_test, lasso_predictions, color='blue', alpha=0.6)\n",
    "axes[0].plot(y_test, y_test, color='red', linewidth=0.5)\n",
    "axes[0].set_title('Lasso Model')\n",
    "axes[0].set_xlabel('Actual Values')\n",
    "axes[0].set_ylabel('Predicted Values')\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].scatter(y_test, elastic_predictions, color='green', alpha=0.6)\n",
    "axes[1].plot(y_test, y_test, color='red', linewidth=0.5)\n",
    "axes[1].set_title('Elastic Model')\n",
    "axes[1].set_xlabel('Actual Values')\n",
    "axes[1].set_ylabel('Predicted Values')\n",
    "axes[1].grid(True)\n",
    "\n",
    "axes[2].scatter(y_test, sgd_predictions, color='hotpink', alpha=0.6)\n",
    "axes[2].plot(y_test, y_test, color='red', linewidth=0.5)\n",
    "axes[2].set_title('SGD Model')\n",
    "axes[2].set_xlabel('Actual Values')\n",
    "axes[2].set_ylabel('Predicted Values')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 6 : Results and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* scikit-learn. (2024). Choosing the right estimator [Online] Available at: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html [Accessed 11 April 2024].\n",
    "\n",
    "* Sarah El Shatby. (2022). Predictive Model in Python. [Online] Available at: https://365datascience.com/tutorials/python-tutorials/predictive-model-python/ [Accessed 11 April 2024].\n",
    "\n",
    "* Saturn Cloud. (2023). Python Classification with Lasso: How to Predict Classes. [Online] Available at: https://saturncloud.io/blog/python-classification-with-lasso-how-to-predict-classes/#:~:text=Feature%20Selection%3A%20Lasso%20automatically%20selects,feature%2Dto%2Dsample%20ratio. [Accessed 11 April 2024].\n",
    "\n",
    "* scikit-learn developers. (2024). Imputation of missing values. [Online] Available at: https://scikit-learn.org/stable/modules/impute.html [Accessed 11 April 2024]\n",
    "\n",
    "* plotly (2024). Scatter Plots in Python [Online] Available at: https://plotly.com/python/line-and-scatter/ [Accessed 13 April 2024].\n",
    "\n",
    "* scikit-learn (n.d.) 'Preprocessing data', scikit-learn Documentation, [Online]. Available at: https://scikit-learn.org/stable/modules/preprocessing.html (Accessed: 13 April 2024).\n",
    "\n",
    "* IBM Developer. (2024). Lasso regression: Automatic feature selection. [Online] Available at: https://developer.ibm.com/tutorials/awb-lasso-regression-automatic-feature-selection/ [Accessed 12 April 2024].\n",
    "\n",
    "* Stephy Daniel. (2022). Model Evaluation for Classification and Regression Analysis. [Online] Available at: https://medium.com/@stephy.SD99/model-evaluation-for-classification-and-regression-analysis-6fa2d11a4a09 [Accessed 12 April 2024].\n",
    "\n",
    "* LinkedIn. (n.d.) 'How Do You Interpret Coefficients - Elastic?', LinkedIn. Available at: https://www.linkedin.com/advice/0/how-do-you-interpret-coefficients-elastic#:~:text=The%20parameters%20of%20elastic%20net%20regression%20are%20alpha%20and%20lambda,the%20performance%20of%20the%20model. (Accessed: 17 April 2024).\n",
    "\n",
    "* Hackernoon. (2018) 'An Introduction to Ridge, Lasso, and Elastic Net Regression,' Hacker Noon. Available at: https://hackernoon.com/an-introduction-to-ridge-lasso-and-elastic-net-regression-cca60b4b934f (Accessed: 17 April 2024).\n",
    "\n",
    "* Brownlee, J. (2023) 'k-Fold Cross-Validation', Machine Learning Mastery, [Online]. Available at: https://machinelearningmastery.com/k-fold-cross-validation/ (Accessed: 17 April 2024).\n",
    "\n",
    "* scikit-learn (n.d.) 'ElasticNet', scikit-learn Documentation, [Online]. Available at: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html (Accessed 11 April 2024).\n",
    "\n",
    "* atoti (n.d.) 'When to Perform a Feature Scaling', atoti Articles, [Online]. Available at: https://www.atoti.io/articles/when-to-perform-a-feature-scaling/#:~:text=In%20regression%2C%20it%20is%20often,are%20set%20to%20their%20means (Accessed 11 April 2024).\n",
    "\n",
    "* ai-jobs.net (2023) 'ElasticNet Explained', AI Jobs, [Online]. Available at: https://ai-jobs.net/insights/elasticnet-explained/#:~:text=Data%20Scaling%3A%20It%20is%20essential,from%20dominating%20the%20regularization%20process (Accessed: 21 April 2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, all the models yielded almost identical results after fine-tuning, with the best Lasso model having an alpha value of 0.0203 and achieving an MSE of 0.3784 and an R2 of 0.7525. The best ElasticNet model had an alpha of 0.05 and an L1 ratio of 0.2121, resulting in an MSE of 0.3813 and an R2 of 0.7506. Similarly, the SGD model with an alpha of 0.0203 and an L1 ratio of 0.0 achieved an MSE of 0.3877 and an R2 of 0.7464.\n",
    "\n",
    "During the fine-tuning stage, testing a range of values from 0.0001 to 1 for the SGD and Lasso models, and 0.01 to 1 for the ElasticNet model, found that the optimal alpha values were 0.0203 fro both, leading to a slight improvement in predictions. Additionally, the best alpha ratio for the ElasticNet model was found to be 0.5.\n",
    "\n",
    "The MSE results for both models after fine-tuning showed a significant improvement compared to the initial values of 0.77, with the refined models achieving approximately 0.39. This suggests that the predicted life ladder values are much closer to the actual values, as a lower MSE indicates better model performance.\n",
    "\n",
    "Furthermore, the R-squared (R2) values indicated that all models can predict approximately 75% of the variance in the target variable. This represents a notable improvement from the pre-fine-tuning R2 values of 0.49 for both the Lasso and Elastic, and -4.279688189418018e+23 for the SGD.\n",
    "\n",
    "The biggest improvement through feature scaling and fine tuning was for the SGD model, leading to near identcal results as teh other two models.\n",
    "\n",
    "Despite the relatively close approximation, there remains a discernible gap between the predicted and actual values. Further investigation into the factors contributing to this variance is necessary to enhance the accuracy of the models and improve their predictive capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
